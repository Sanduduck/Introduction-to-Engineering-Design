#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ‘ AI ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ì„œë²„
KoSimCSE ëª¨ë¸ì„ ì‚¬ìš©í•œ í•œêµ­ì–´ ì„ë² ë”© ê²€ìƒ‰
"""

from fastapi import FastAPI, Query

# CORS ë¯¸ë“¤ì›¨ì–´ ì„í¬íŠ¸
from fastapi.middleware.cors import CORSMiddleware 
'''
CORSë¥¼ ì¼œê¸° ìœ„í•œ ë¯¸ë“¤ì›¨ì–´ì…ë‹ˆë‹¤. 
CORSëŠ” â€œë‹¤ë¥¸ ë„ë©”ì¸Â·í¬íŠ¸ì—ì„œ ì˜¤ëŠ” ìš”ì²­ì„ í—ˆìš©í• ì§€ ë§ì§€â€ë¥¼ ì •í•˜ëŠ” ì›¹ ê·œì¹™
ë¸Œë¼ìš°ì €ëŠ” ì´ê±¸ ì•ˆ í•´ì£¼ë©´ JSë¡œ APIë¥¼ ëª» ë¶€ë¦„
'''

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import json
import uvicorn
import os

app = FastAPI() # FastAPI ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ í•˜ë‚˜ ë§Œë“­ë‹ˆë‹¤.

# ğŸ‘ CORS ì„¤ì • - Express ì„œë²„ì™€ í†µì‹  í—ˆìš©

'''ì´ ì½”ë“œëŠ” â€œì´ íŒŒì´ì¬ ì„œë²„(8000ë²ˆ)ì— ë‹¤ë¥¸ í¬íŠ¸(3000ë²ˆ, 3001ë²ˆ)ì—ì„œ ì˜¤ëŠ” ìš”ì²­ì„ í—ˆìš©í•´ë¼â€ëŠ” ì„¤ì •
    ì›¹ë¸Œë¼ìš°ì €ê°€ ê¸°ë³¸ì ìœ¼ë¡œ ë§‰ëŠ” ê±¸ ì—´ì–´ì£¼ëŠ” ê±°ë‹¤. CORS ì„¤ì •ì´ë¼ê³  ë¶€ë¥¸ë‹¤
'''
app.add_middleware( 
#   app.add_middleware(CORSMiddleware, ...)
#   FastAPI ì•±ì— â€œë¯¸ë“¤ì›¨ì–´â€ë¥¼ í•˜ë‚˜ ë¼ì›Œ ë„£ëŠ”ë‹¤ëŠ” ëœ»ì´ë‹¤.
#   ì´ ë¯¸ë“¤ì›¨ì–´ëŠ” ë“¤ì–´ì˜¤ëŠ” ìš”ì²­ë§ˆë‹¤ CORS ê´€ë ¨ í—¤ë”ë¥¼ ë¶™ì—¬ì¤€ë‹¤.
#   ì•ˆ ë¶™ì´ë©´ ë¸Œë¼ìš°ì €ê°€ â€œë‹¤ë¥¸ í¬íŠ¸ì—ì„œ ì˜¨ ìš”ì²­ì´ë‹ˆê¹Œ ìœ„í—˜í•´â€ í•˜ê³  ë§‰ëŠ”ë‹¤.

    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001", "*"],

#   allow_origins=["http://localhost:3000", "http://localhost:3001", "*"]
#   originì€ â€œì–´ë””ì„œ ì´ APIë¥¼ ë¶€ë¥´ëƒâ€ì´ë‹¤. ì£¼ì†Œ+í¬íŠ¸ê¹Œì§€ í¬í•¨ì´ë‹¤.
#   http://localhost:3000 â† React/Node í”„ëŸ°íŠ¸ ê°œë°œì„œë²„
#   ì˜ˆ: http://localhost:3001 â† ë˜ ë‹¤ë¥¸ í”„ëŸ°íŠ¸
#   ì—¬ê¸°ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê±´ 3000ì´ë‹¤. ì™œëƒí•˜ë©´ ë„ˆì˜ Express/Reactê°€ 3000ì—ì„œ ëŒê³ , 
#  ì´ íŒŒì´ì¬ì€ 8000ì—ì„œ ë„ë‹ˆê¹Œ â€œí¬íŠ¸ê°€ ë‹¤ë¥´ë‹¤.â€ í¬íŠ¸ê°€ ë‹¤ë¥´ë©´ ë¸Œë¼ìš°ì €ëŠ” CORSë¥¼ ê²€ì‚¬í•œë‹¤
#  ê·¸ë˜ì„œ 3000, 3001ì—ì„œ ì˜¤ëŠ” ìš”ì²­ì€ í—ˆìš©í•´~~~ ë¼ëŠ” ê±´ë°, ìš°ë¦° *ë„ ë„£ì—ˆëŠ”ë° "*"ì€ ê± ë‹¤ í—ˆìš©í•˜ë¼ëŠ”ê±°ì„, ì´ê±´ ê·¸ëƒ¥ ê°œë°œ í¸ì˜ë¥¼ ìœ„í•œ ê±°ë‹ˆê¹Œ ë‚˜ì¤‘ì— ìš´ì˜í•  ë•ŒëŠ” ë¹¼ëŠ” ê²Œ ì¢‹ìŒ
    allow_credentials=True, #â€œì¿ í‚¤, Authorization í—¤ë” ê°™ì€ ì¸ì¦ ì •ë³´ë„ ë³´ë‚´ë„ ëœë‹¤â€ëŠ” ëœ»ì´ë‹¤.
    allow_methods=["*"], # â€œëª¨ë“  HTTP ë©”ì„œë“œ(GET, POST, PUT, DELETE ë“±)ë¥¼ í—ˆìš©í•œë‹¤â€ëŠ” ëœ»
    allow_headers=["*"], # â€œëª¨ë“  í—¤ë”ë¥¼ í—ˆìš©í•œë‹¤â€ëŠ” ëœ», Content-Type: application/json, Authorization: Bearer ... ì´ëŸ° ê²ƒë„ ë‹¤ í—ˆìš©.
)

# ğŸ‘ ë°ì´í„° ë° ëª¨ë¸ ì´ˆê¸°í™”, models.json(ê²€ìƒ‰ ëŒ€ìƒ) ì½ê¸°
print("ğŸ‘ ëª¨ë¸ ë¡œë”© ì¤‘...")

# models.json ê²½ë¡œ - data í´ë”ì™€ public í´ë” ë‘˜ ë‹¤ ì²´í¬
MODEL_PATH = None
for path in ["data/models.json", "public/models.json"]:
    if os.path.exists(path):
        MODEL_PATH = path
        break

if not MODEL_PATH:
    print("âš ï¸ models.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    MODELS = []
else:
    with open(MODEL_PATH, "r", encoding="utf-8") as f:
        MODELS = json.load(f)
    print(f"ğŸ‘ {len(MODELS)}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

# ğŸ‘ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸), â€œAIê°€ ë¬¸ì¥ì„ ìˆ«ìë¡œ ë°”ê¾¸ëŠ” ëª¨ë¸(ì„ë² ë”© ëª¨ë¸)â€ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë¶€ë¶„
try:
    # í•œêµ­ì–´ ì§€ì› ëª¨ë¸ë“¤ ì‹œë„
    model_name = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"  # ë‹¤êµ­ì–´ ëª¨ë¸
    embed_model = SentenceTransformer(model_name)

    '''
    SentenceTransformer(...)ëŠ” Hugging Face Hubì—ì„œ ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ì„ ìë™ ë‹¤ìš´ë¡œë“œí•œë‹¤.
    ì´ ëª¨ë¸ì€ â€œë‹¤êµ­ì–´ ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸â€ë¡œ, ì˜ì–´ë¿ ì•„ë‹ˆë¼ í•œêµ­ì–´Â·ì¤‘êµ­ì–´ ë“± ì•½ 50ê°œ ì–¸ì–´ë¥¼ ì§€ì›í•œë‹¤.  
    â€˜ë¬¸ì¥ â†’ ë²¡í„°â€™ë¡œ ë³€í™˜í•´ ì£¼ë¯€ë¡œ,
    â€œë¡œë´‡ íŒ” ì œì–´â€ì™€ â€œë¡œë´‡ ì œì–´ ë°©ë²•â€ ê°™ì€ ë¹„ìŠ·í•œ ë¬¸ì¥ì´ ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œì´ ìœ„ì¹˜í•œë‹¤.
    ê·¸ë˜ì„œ ë‹¨ìˆœ ë‹¨ì–´ ê²€ìƒ‰ì´ ì•„ë‹ˆë¼ ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ ë¬¸ì¥ ê²€ìƒ‰ì´ ê°€ëŠ¥í•´ì§„ë‹¤.
    '''
    print(f"ğŸ‘ ë‹¤êµ­ì–´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")

except Exception as e:
    print(f"âš ï¸ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    # ê¸°ë³¸ ëª¨ë¸ë¡œ í´ë°±
    embed_model = SentenceTransformer("all-MiniLM-L6-v2")
    print("ğŸ‘ ê¸°ë³¸ ì˜ì–´ ëª¨ë¸ë¡œ ëŒ€ì²´ ë¡œë“œ")

# ğŸ‘ ë¬¸ì„œ ì„ë² ë”© ìƒì„± (title + description)
if MODELS: 
    """
    ì•ì—ì„œ models.jsonì„ ëª» ì½ì—ˆìœ¼ë©´ MODELS = []ì˜€ë‹¤.
    ë¹ˆ ë¦¬ìŠ¤íŠ¸ë©´ ì„ë² ë”© ë§Œë“¤ í•„ìš”ê°€ ì—†ìœ¼ë‹ˆ ë°”ë¡œ index = Noneìœ¼ë¡œ ë‘ê³  ëë‚¸ë‹¤.
    ì¦‰ â€œê²€ìƒ‰í•  ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œâ€ ì„ë² ë”©ê³¼ FAISSë¥¼ ë§Œë“ ë‹¤.
    """
    doc_texts = []
    for m in MODELS:
        title = m.get("title", "")
        description = m.get("description", "")
        # ê³¼ëª© ì •ë³´ë„ í¬í•¨í•˜ë©´ ë” ì •í™•í•œ ê²€ìƒ‰ ê°€ëŠ¥
        subject = m.get("subject", "")
        combined = f"{title} {description} {subject}"
        doc_texts.append(combined)

    print("ğŸ‘ ë¬¸ì„œ ì„ë² ë”© ìƒì„± ì¤‘...")
    doc_embeddings = embed_model.encode(doc_texts, show_progress_bar=True)

    # ğŸ‘ FAISS ì¸ë±ìŠ¤ ìƒì„± (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
    dimension = doc_embeddings.shape[1]
    index = faiss.IndexFlatIP(dimension)  # Inner Product = Cosine similarity (ì •ê·œí™”ëœ ë²¡í„°)

    # L2 ì •ê·œí™”ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì¤€ë¹„
    faiss.normalize_L2(doc_embeddings)
    index.add(doc_embeddings.astype('float32'))
    print(f"ğŸ‘ FAISS ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ (ì°¨ì›: {dimension})")
    # ì´ ë¶€ë¶„ ì–´ë ¤ìš¸ ìˆ˜ë„ ìˆëŠ”ë° ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê±°ë¦¬ëŠ” ê± ì˜ë¯¸ê°€ ê°€ê¹Œìš´ì§€ ë¨¼ì§€ ì¬ëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ë¼ê³  ìƒê°í•˜ë©´ ë¨
else:
    index = None
    doc_embeddings = None

@app.get("/")
def root():
    """ğŸ‘ ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "running",
        "message": "ğŸ‘ AI ì˜ë¯¸ ê²€ìƒ‰ ì„œë²„ ì‹¤í–‰ ì¤‘",
        "models_count": len(MODELS),
        "model_name": "paraphrase-multilingual-mpnet-base-v2"
    }

@app.get("/semantic_search")
def semantic_search(
    q: str = Query(..., description="ê²€ìƒ‰ ì¿¼ë¦¬"),
    k: int = Query(20, description="ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜", ge=1, le=20)
):
    """
    ğŸ‘ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ API

    Args:
        q: ê²€ìƒ‰ì–´
        k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜ (ìµœëŒ€ le = 20)

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ (id, title, description, score)
    """

    if not index or not MODELS:
        return {"error": "ì¸ë±ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", "results": []}

    # ğŸ‘ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = embed_model.encode([q])
    faiss.normalize_L2(query_embedding)

    # ğŸ‘ ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
    k = min(k, len(MODELS))  # kê°€ ì „ì²´ ë¬¸ì„œ ìˆ˜ë³´ë‹¤ í¬ë©´ ì¡°ì •
    distances, indices = index.search(query_embedding.astype('float32'), k)

    # ğŸ‘ ê²°ê³¼ í¬ë§·íŒ…
    results = []
    for score, idx in zip(distances[0], indices[0]):
        # ğŸ‘ Score 0.3 ì´ìƒë§Œ í•„í„°ë§ (30% ì´ìƒ ìœ ì‚¬ë„)
        if idx < len(MODELS) and score >= 0.25:  # ì¸ë±ìŠ¤ ë²”ìœ„ ì²´í¬ + score í•„í„°ë§
            item = MODELS[idx]
            results.append({
                "id": item.get("id", idx),
                "title": item.get("title", ""),
                "description": item.get("description", ""),
                "subject": item.get("subject", ""),
                "score": float(score),  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (0~1)
                "rank": len(results) + 1
            })

    return {
        "query": q,
        "count": len(results),
        "results": results,
        "method": "semantic_search",
        "model": "multilingual-mpnet"
    }

@app.get("/health")
def health_check():
    """ğŸ‘ í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "models_loaded": len(MODELS)}

if __name__ == "__main__":
    # ğŸ‘ ì„œë²„ ì‹¤í–‰ (í¬íŠ¸ 8000)
    print("ğŸ‘ AI ì˜ë¯¸ ê²€ìƒ‰ ì„œë²„ ì‹œì‘: http://localhost:8000")
    print("ğŸ‘ API ë¬¸ì„œ: http://localhost:8000/docs")
    uvicorn.run("semantic_search:app", host="0.0.0.0", port=8000, reload=True)